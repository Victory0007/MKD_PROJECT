{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unable to read image C:/Users/DELL  LATITUDE E5480/Downloads/MKD_DS_PROJECT/img_dataset_dir\\LUNCH_BAG_WOODLAND\\085aa751-04cd-47af-99c7-c1d1baa7e5a5.zip\n"
     ]
    }
   ],
   "source": [
    "#Creating dataset: Converting images to numpy arrays and assigning labels to them\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "def rescale_images(directory, size):\n",
    "    \"\"\"\n",
    "    Resizes all images in a directory to the specified size using OpenCV.\n",
    "\n",
    "    Parameters:\n",
    "    - directory: Path to the directory containing folders, each with images.\n",
    "    - size: Tuple (width, height) to resize images.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    for foldername in os.listdir(directory):\n",
    "        folderpath = os.path.join(directory, foldername)\n",
    "        \n",
    "        # Check if the current item in the directory is a folder\n",
    "        if os.path.isdir(folderpath):\n",
    "            # Iterate through each image in the current folder\n",
    "            for img_name in os.listdir(folderpath):\n",
    "                img_path = os.path.join(folderpath, img_name)\n",
    "                \n",
    "                # Read the image using cv2.imread\n",
    "                im = cv2.imread(img_path)\n",
    "                \n",
    "                # Check if the image was successfully read\n",
    "                if im is None:\n",
    "                    print(f\"Error: Unable to read image {img_path}\")\n",
    "                    continue\n",
    "                \n",
    "                # Resize the image using cv2.resize\n",
    "                im_resized = cv2.resize(im, size, interpolation=cv2.INTER_AREA)\n",
    "                \n",
    "                # Save the resized image with a new name or to a different directory\n",
    "                # Example: Save resized images to a new directory\n",
    "                resized_dir = os.path.join(directory, 'resized_images')\n",
    "                if not os.path.exists(resized_dir):\n",
    "                    os.makedirs(resized_dir)\n",
    "                \n",
    "                resized_img_path = os.path.join(resized_dir, f'{foldername}_{img_name}')\n",
    "                cv2.imwrite(resized_img_path, im_resized)\n",
    "\n",
    "\n",
    "# Define the path to your dataset directory\n",
    "dataset_dir = 'C:/Users/DELL  LATITUDE E5480/Downloads/MKD_DS_PROJECT/img_dataset_dir'\n",
    "\n",
    "# Rescale images to a fixed size (e.g., 256x256)\n",
    "rescale_images(dataset_dir, (256, 256))\n",
    "\n",
    "# Initialize lists to store images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Iterate through each folder (class) in the dataset directory\n",
    "for foldername in os.listdir(dataset_dir):\n",
    "    folderpath = os.path.join(dataset_dir, foldername)\n",
    "    \n",
    "    # Iterate through each image in the current folder\n",
    "    for filename in os.listdir(folderpath):\n",
    "        imagepath = os.path.join(folderpath, filename)\n",
    "        \n",
    "        # Open the image using PIL\n",
    "        #image = Image.open(imagepath)\n",
    "        print(imagepath)\n",
    "        image = cv2.imread(imagepath)\n",
    "        \n",
    "        # Convert the image to numpy array and rescale pixel values to [0, 1]\n",
    "        image = np.array(image) / 255.0\n",
    "        \n",
    "        # Append the image to the images list\n",
    "        images.append(image)\n",
    "        \n",
    "        # Append the label (which is the folder name) to the labels list\n",
    "        labels.append(foldername)\n",
    "\n",
    "# Convert lists to numpy arrays for easier manipulation\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Optionally, you can visualize one of the images\n",
    "plt.imshow(images[0])  # Adjust index as needed\n",
    "plt.title(labels[0])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Now you have your dataset ready with resized and rescaled images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBUi4j-G-2Et"
   },
   "source": [
    "# **Loading, Inspecting and Visualising our data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYx94TSr-8Ot"
   },
   "source": [
    "### **Inspect our Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dqtlmgNwkEqm",
    "outputId": "5537bf11-6006-416f-bdbe-22b7d1dde238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape or dimensions of x_train (60000, 28, 28)\n",
      "Number of samples in our training data: 60000\n",
      "Number of labels in our training data: 60000\n",
      "Number of samples in our test data: 10000\n",
      "Number of labels in our test data: 10000\n",
      "\n",
      "\n",
      "Dimensions of x_train:(28, 28)\n",
      "Labels in x_train:(60000,)\n",
      "\n",
      "\n",
      "Dimensions of x_test:(28, 28)\n",
      "Labels in y_test:(10000,)\n"
     ]
    }
   ],
   "source": [
    "# Display the number of samples in x_train, x_test, y_train, y_test\n",
    "print(\"Initial shape or dimensions of x_train\", str(x_train.shape))\n",
    "\n",
    "# Print the number of samples in our data\n",
    "print (\"Number of samples in our training data: \" + str(len(x_train)))\n",
    "print (\"Number of labels in our training data: \" + str(len(y_train)))\n",
    "print (\"Number of samples in our test data: \" + str(len(x_test)))\n",
    "print (\"Number of labels in our test data: \" + str(len(y_test)))\n",
    "\n",
    "# Print the image dimensions and no. of labels in our Training and Test Data\n",
    "print(\"\\n\")\n",
    "print (\"Dimensions of x_train:\" + str(x_train[0].shape))\n",
    "print (\"Labels in x_train:\" + str(y_train.shape))\n",
    "print(\"\\n\")\n",
    "print (\"Dimensions of x_test:\" + str(x_test[0].shape))\n",
    "print (\"Labels in y_test:\" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVNejpu8_CMl"
   },
   "source": [
    "### **Visualizing some of our sample Data**\n",
    "\n",
    "Let's plot 50 sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "-9fItIVInCaE",
    "outputId": "484bb4f8-b146-46ae-8fe8-ba091e764820"
   },
   "outputs": [],
   "source": [
    "# Let's view the 50 first images of the MNIST training dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create figure and change size\n",
    "figure = plt.figure()\n",
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "# Set how many images we wish to see\n",
    "num_of_images = 50\n",
    "\n",
    "# iterate index from 1 to 51\n",
    "for index in range(1, num_of_images + 1):\n",
    "    class_names = classes[y_train[index]]\n",
    "    plt.subplot(5, 10, index).set_title(f'{class_names}')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(x_train[index], cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJ0hE9rA_G6d"
   },
   "source": [
    "# **2. Data Preprocessing using ImageDataGenerator**\n",
    "\n",
    "First we reshape and change our data types as we had done previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EJ-HShDRnLos"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Reshape our data to be in the format [number of samples, width, height, color_depth]\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "# Change datatype to float32\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPWfM47S_1Y1"
   },
   "source": [
    "**We gather our image size, shape and Normalize our Test Data**\n",
    "\n",
    "We will use the ImageDataGenerator to Normalize and provide Data Augmentations for our **Training Data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TvHnFfhsI1Uh"
   },
   "outputs": [],
   "source": [
    "# Lets store the number of rows and columns\n",
    "img_rows = x_train[0].shape[0]\n",
    "img_cols = x_train[0].shape[1]\n",
    "\n",
    "# store the shape of a single image\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# Normalize our data between 0 and 1\n",
    "x_test /= 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJYA4pwkAJhk"
   },
   "source": [
    "### **One Hot Encode our Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DtWQpsKy3I8T",
    "outputId": "aac0465e-b7da-4f4d-c8d2-fe410f759995"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Classes: 10\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Now we one hot encode outputs\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Let's count the number columns in our hot encoded matrix\n",
    "print (\"Number of Classes: \" + str(y_test.shape[1]))\n",
    "\n",
    "num_classes = y_test.shape[1]\n",
    "num_pixels = x_train.shape[1] * x_train.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pVXX0rZAOIG"
   },
   "source": [
    "# **3. Building Our Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ejn_tLCDnWLv",
    "outputId": "6a19b83e-c744-4cf0-d5c9-87bf25e1b751"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "L2 = 0.001\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_regularizer = regularizers.l2(L2),\n",
    "                 input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer = regularizers.l2(L2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu',kernel_regularizer = regularizers.l2(L2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = tf.keras.optimizers.SGD(0.001, momentum=0.9),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XI121EHEB67I"
   },
   "source": [
    "# **Training Our Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A7NPPgG9y3bQ",
    "outputId": "5525d560-73e1-4f05-bd30-56ec0d1a8bb4"
   },
   "outputs": [],
   "source": [
    "# Define Data Generator for Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "# Here we fit the data generator to some sample data.\n",
    "#train_datagen.fit(x_train)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 15\n",
    "\n",
    "# Fit the model\n",
    "# Notice we use train_datagen.flow, this takes data & label arrays, generates batches of augmented data.\n",
    "history = model.fit(train_datagen.flow(x_train, y_train, batch_size = batch_size),\n",
    "                              epochs = epochs,\n",
    "                              validation_data = (x_test, y_test),\n",
    "                              verbose = 1,\n",
    "                              steps_per_epoch = x_train.shape[0] // batch_size)\n",
    "\n",
    "# We obtain our accuracy score using the evalute function\n",
    "# Score holds two values, our Test loss and Accuracy\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ii_fI-C-CJVF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
